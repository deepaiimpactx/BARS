services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 5

  broker:
    image: confluentinc/cp-kafka:7.4.0
    hostname: broker
    container_name: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092, PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    healthcheck:
      test: [ "CMD", "bash", "-c", 'nc -z localhost 9092' ]
      interval: 10s
      timeout: 5s
      retries: 5

  schema-registry:
    image: confluentinc/cp-schema-registry:7.4.0
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      broker:
        condition: service_healthy
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'broker:29092'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8081/" ]
      interval: 30s
      timeout: 10s
      retries: 5

  control-center:
    image: confluentinc/cp-enterprise-control-center:7.4.0
    hostname: control-center
    container_name: control-center
    depends_on:
      broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "http://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      PORT: 9021
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9021/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

#  postgres:
#    image: postgres:latest
#    container_name: postgres
#    ports:
#      - "5432:5432"
#    environment:
#      POSTGRES_USER: postgres
#      POSTGRES_PASSWORD: postgres
#      POSTGRES_DB: postgres
#    healthcheck:
#      test: [ "CMD", "pg_isready", "-U", "postgres" ]
#      interval: 10s
#      timeout: 5s
#      retries: 5
#    volumes:
#      - ./initdb:/docker-entrypoint-initdb.d

  flask_api:
    build: ./kafka/api
    ports:
      - "5001:5000"
    depends_on:
      - broker
      #- postgres

#  kafka-consumer:
#    build: ./kafka/consumer
#    container_name: KafkaConsumer
#    depends_on:
#      - broker
#      - postgres
#    environment:
#      KAFKA_BROKER: 'broker:29092'
#      POSTGRES_HOST: 'postgres'
#      POSTGRES_PORT: '5432'
#      POSTGRES_DB: 'postgres'
#      POSTGRES_USER: 'postgres'
#      POSTGRES_PASSWORD: 'postgres'

  flink-jobmanager:
    build:
      context: ./pyflink
      dockerfile: Dockerfile
    ports:
      - "7071:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
    command: jobmanager
    depends_on:
      - zookeeper
      - broker
    volumes:
      - ./pyflink/saved_models:/opt/flink/saved_models
      - ./pyflink/usr_jobs:/opt/flink/usr_jobs


  flink-taskmanager:
    build:
      context: ./pyflink
      dockerfile: Dockerfile
    depends_on:
      - flink-jobmanager
    command: taskmanager
    scale: 1
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 5
    volumes:
      - ./pyflink/saved_models:/opt/flink/saved_models
      - ./pyflink/usr_jobs:/opt/flink/usr_jobs

#  dash-app:
#    build: ./dash
#    container_name: Dashboard
#    ports:
#        - "5000:5000"
#    volumes:
#      - ./uploads:/uploads


#  airflow_webserver:
#    image: apache/airflow:2.9.1-python3.8
#    container_name: airflow_webserver
#    restart: always
#    depends_on:
#      - postgres
#    ports:
#      - "8080:8080"
#    environment:
#      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres/postgres
#      AIRFLOW__WEBSERVER__SECRET_KEY: "change_this_key"
#      AIRFLOW__CORE__FERNET_KEY: "rBWG3kwVfz7dvIuEugu7ErYD6y3oAuIZb2AYEYVTd8U="
#      AIRFLOW__WEBSERVER__AUTHENTICATE: "True"
#      AIRFLOW__WEBSERVER__AUTH_BACKEND: "airflow.contrib.auth.backends.password_auth"
#    command: ["bash", "-c", "airflow db init && airflow webserver"]
#
#  airflow_scheduler:
#    image: apache/airflow:2.9.1-python3.8
#    container_name: airflow_scheduler
#    restart: always
#    depends_on:
#      - postgres
#    environment:
#      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@postgres/postgres
#      AIRFLOW__CORE__EXECUTOR: LocalExecutor
#    command: ["bash", "-c", "airflow db init && airflow scheduler"]

#  cassandra_db:
#    image: cassandra:latest
#    container_name: cassandra
#    hostname: cassandra
#    ports:
#      - "9042:9042"
#    environment:
#      - MAX_HEAP_SIZE=512M
#      - HEAP_NEWSIZE=100M
#      - CASSANDRA_USERNAME=cassandra
#      - CASSANDRA_PASSWORD=cassandra
#    volumes:
#      - ./maliciousIPs/setup.cql:/setup.cql
#      - ./maliciousIPs/entrypoint.sh:/entrypoint.sh
#    entrypoint: ["/entrypoint.sh"]
#
#  bloom_filter:
#    build: ./bloomFilter
#    container_name: BloomFilter
#    depends_on:
#      - broker
#      - cassandra_db
#    environment:
#      CASSANDRA_HOST: cassandra_db
#      CASSANDRA_KEYSPACE: malicious_ip
#      KAFKA_BROKER: broker:29092
#      KAFKA_TOPIC: sensor_data_topic
#      KAFKA_GROUP: kafka_sink_group
#
#  malicious_ip_query_result:
#    build: ./kafka/maliciousIpConsumer
#    container_name: maliciousIpConsumer
#    depends_on:

#      - bloom_filter

